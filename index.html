<html>

<head>
    <title>Video Frame Capture</title>
    <script>
        // Change this value from a "Stop button";
        var stopped = false;
        var started = false;
        var imageFrames = []
        function createVideo() {
            return document.createElement('video')
        }
        function createDiv() {
            return document.createElement('div')
        }
        function createCanvas() {
            return document.createElement('canvas')
        }
        function stopVideoCapture() {
            stopped = true
        }
        async function startVideoCapture() {
            if(started){
                return;
            }
            started=true
            const start = Date.now()
            const output = document.querySelector('#output')
            output.innerHTML =''
            const statusDiv = createDiv()
            statusDiv.append('Processing')
            output.append(statusDiv)
            const video = createVideo()
            video.src = 'mov_bbb.mp4' //pass this as input
            let seekComplete;
            video.onseeked = async (event) => {
                if (seekComplete) seekComplete();
                /**
                 * The seeked event is fired when a seek operation completed,
                 * the current playback position has changed,
                 * and the Boolean seeking attribute is changed to false.
                 */
            };
            // workaround chromium metadata bug (https://stackoverflow.com/q/38062864/993683)
            while (
                (video.duration === Infinity || isNaN(video.duration)) &&
                video.readyState < 2
            ) {
                await new Promise((r) => setTimeout(r, 1000));
            }

            video.crossOrigin = "Anonymous";
            video.height = 160; // this will be coming from configuration as an input
            video.width = 320; // this will be coming from configuration as an input
            const canvas = createCanvas();
            canvas.width = video.width;
            canvas.height = video.height;
            var ctx = canvas.getContext('2d');
            var track = video.captureStream().getVideoTracks()[0];
            var processor = new MediaStreamTrackProcessor(track);
            const frameReader = processor.readable.getReader();
            stopped = false
            const FPS = 25// this will be coming from configuration as an input
            const totalExpectedFrames = Math.floor(FPS * video.duration) // this will be coming from configuration as an input


            const intervalPerFrame = 1 / FPS; // 0.1 sec
            let currentTime = intervalPerFrame;
            let i = 0;
            output.removeChild(statusDiv)
            statusDiv.innerHTML = `Capturing ${i} of ${totalExpectedFrames} frames`
            output.append(statusDiv)
            video.currentTime = 0.01;
            await new Promise(r => seekComplete = r);
            frameReader.read().then(async function processFrame({ done, value }) {

                if (done) {
                    console.log("Stream is done");
                    return;
                }

                if (stopped) { // brute force stop handler
                    frameReader.releaseLock();
                    processor.readable.cancel();
                    value.close();
                    console.log("Stopped");
                    video.remove();
                    console.log(imageFrames)
                    output.removeChild(statusDiv)
                    imageFrames.map((frame) => {
                        const img = new Image();
                        img.src = frame.url;
                        img.width = video.width;
                        img.height = video.height;
                        img.style.padding = "5px 5px 5px 5px"
                        img.style.objectFit = 'contain'
                        img.style.borderRadius = '10px'
                        output.append(img)
                    })
                    const end = new Date().getTime()
                    var timeDiff = end - start; //in ms
                    // strip the ms
                    timeDiff /= 1000;

                    // get seconds 
                    var seconds = Math.round(timeDiff);
                    statusDiv.innerHTML = `Completed ${i} of ${totalExpectedFrames} frames. Elapsed time ${seconds} secs`
                    output.append(statusDiv)
                    started=false
                    return;
                }

                var img = await createImageBitmap(value);
                ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
                i++
                statusDiv.innerHTML = `Capturing ${i} of ${totalExpectedFrames} frames`
                output.append(statusDiv)
                canvas.toBlob(async (blob) => {
                    const url = URL.createObjectURL(blob)

                    imageFrames.push({
                        id: i,
                        img,
                        url,
                        t: currentTime
                    })
                    currentTime += intervalPerFrame;
                    console.log(`frame#${i}`, url)
                    img.close();
                    value.close();
                    if (i == totalExpectedFrames) {
                        // streaming of video completes
                        console.log("stream done");
                        stopped = true;
                        done = true;
                        frameReader.releaseLock();
                        processor.readable.cancel();
                        value.close();
                        console.log("Stopped");
                        video.remove();
                        console.log(imageFrames)
                        output.removeChild(statusDiv)
                        imageFrames.map((frame) => {
                            const img = new Image();
                            img.src = frame.url;
                            img.width = video.width;
                            img.height = video.height;
                            img.style.objectFit = 'contain'
                            img.style.borderRadius = '10px'
                            img.style.padding = "5px 5px 5px 5px"
                            output.append(img)
                        })

                        const end = new Date().getTime()
                        var timeDiff = end - start; //in ms
                        // strip the ms
                        timeDiff /= 1000;

                        // get seconds 
                        var seconds = Math.round(timeDiff);
                        statusDiv.innerHTML = `Completed ${i} of ${totalExpectedFrames} frames. Elapsed time ${seconds} secs`
                        output.append(statusDiv)
                        started=false
                        return
                    }

                    video.currentTime = currentTime;
                    await new Promise(r => seekComplete = r);
                    frameReader.read().then(processFrame);
                })
            })
        }

    </script>
</head>

<body>
    <h1>Capture video frames with web codecs</h1>
    <video id="video" width="320" height="160" controls>
        <source src="mov_bbb.mp4" type="video/mp4">
        Your browser does not support HTML5 video.
    </video>
    <div>
        <button onclick="startVideoCapture()" type="button" id="btn">Start capture frames</button>
        <button onclick="stopVideoCapture()" type="button" id="btn-stop">Stop capture frames</button>
        <p>Follow console logs for status, once capture is done, the frames will be visible below..</p>
       
        <small>You don't have to necessarily play the video to start capturing ðŸ˜‰, just click on Start button to begin capturing the video frames ðŸš€</small>
    </div>


    <div id="output">

    </div>
</body>

</html>